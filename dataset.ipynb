{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBDxpzUnON-6"
      },
      "source": [
        "# Jaws Segmentation Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gSVAbBHON_Y",
        "outputId": "98b2355f-3869-4d4e-d477-201336b9eb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: progressbar\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=16915f608ebdd0f4edc403bda1f8c87f785628339d5fa88c1ceb124b42748145\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n",
            "Successfully built progressbar\n",
            "Installing collected packages: progressbar\n",
            "Successfully installed progressbar-2.5\n"
          ]
        }
      ],
      "source": [
        "! pip install --user torch torchvision matplotlib numpy progressbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqh5--UvON_f"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import progressbar\n",
        "from math import ceil\n",
        "import torch\n",
        "import gzip\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JwXNXaB-do5"
      },
      "source": [
        "#### Download_Data (data flag):\n",
        "1. Download_Data = True, if you will download the data online\n",
        "2. Download_Data = False, if you already downloaded the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFad7ZJYON_k"
      },
      "outputs": [],
      "source": [
        "LOCAL_DATASET_PATH = 'dataset'\n",
        "BATCH_SIZE = 16\n",
        "Download_Data = False\n",
        "## data url\n",
        "AXIAL_TRAINING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/axial/train.zip'\n",
        "AXIAL_TESTING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/axial/test.zip'\n",
        "CORONAL_TRAINING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/coronal/train.zip'\n",
        "CORONAL_TESTING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/coronal/test.zip'\n",
        "SAGITTAL_TRAINING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/sagittal/train.zip'\n",
        "SAGITTAL_TESTING_DATASET = 'https://cvml-datasets.s3.eu-west-3.amazonaws.com/jaws-segmentation/v1/public/2d/sagittal/test.zip'\n",
        "## data path after being downloaded\n",
        "down_axial_training_data = 'dataset/axial/train/**/*.dicom.npy.gz'\n",
        "down_axial_testing_data = 'dataset/axial/test/**/*.dicom.npy.gz'\n",
        "down_coronal_training_data = 'dataset/coronal/train/**/*.dicom.npy.gz'\n",
        "down_coronal_testing_data = 'dataset/coronal/test/**/*.dicom.npy.gz'\n",
        "down_sagittal_training_data = 'dataset/sagittal/train/**/*.dicom.npy.gz'\n",
        "down_sagittal_testing_data = 'dataset/sagittal/test/**/*.dicom.npy.gz'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYL1NRszON_o"
      },
      "source": [
        "Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjUDQm8HON_q"
      },
      "outputs": [],
      "source": [
        "download_progress_bar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global download_progress_bar\n",
        "    if download_progress_bar is None:\n",
        "        download_progress_bar = progressbar.ProgressBar(maxval=total_size)\n",
        "        download_progress_bar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        download_progress_bar.update(downloaded)\n",
        "    else:\n",
        "        download_progress_bar.finish()\n",
        "        download_progress_bar = None\n",
        "\n",
        "def download_file(url, disk_path):\n",
        "    print(f'downloading {url}')\n",
        "    filename, _ = urllib.request.urlretrieve(url, reporthook=show_progress)\n",
        "    os.makedirs(disk_path)\n",
        "    with zipfile.ZipFile(filename, 'r') as zip:\n",
        "        zip.extractall(disk_path)\n",
        "\n",
        "def download_data(to=LOCAL_DATASET_PATH):\n",
        "    download_file(AXIAL_TRAINING_DATASET, os.path.join(to, 'axial', 'train'))\n",
        "    download_file(AXIAL_TESTING_DATASET, os.path.join(to, 'axial', 'test'))\n",
        "    download_file(CORONAL_TRAINING_DATASET, os.path.join(to, 'coronal', 'train'))\n",
        "    download_file(CORONAL_TESTING_DATASET, os.path.join(to, 'coronal', 'test'))\n",
        "    download_file(SAGITTAL_TRAINING_DATASET, os.path.join(to, 'sagittal', 'train'))\n",
        "    download_file(SAGITTAL_TESTING_DATASET, os.path.join(to, 'sagittal', 'test'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Download dataset if it is not exist\n",
        "if(Download_Data == True):\n",
        "    download_data()"
      ],
      "metadata": {
        "id": "Aii6NRtD_xN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9DR2ssOON_z"
      },
      "source": [
        "#### Class and methods required to read, split, set in dataloader and plot data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJgaqYdbON_4"
      },
      "outputs": [],
      "source": [
        "class JawsDataset(torch.utils.data.Dataset):\n",
        "\tdef __init__(self, dicom_file_list, transforms):\n",
        "\t\tself.dicom_file_list = dicom_file_list\n",
        "\t\tself.transforms = transforms\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.dicom_file_list)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tdicom_path = self.dicom_file_list[idx]\n",
        "\t\tlabel_path = dicom_path.replace('.dicom.npy.gz', '.label.npy.gz')\n",
        "\t\tdicom_file = gzip.GzipFile(dicom_path, 'rb')\n",
        "\t\tdicom = np.load(dicom_file)\n",
        "\t\tlabel_file = gzip.GzipFile(label_path, 'rb')\n",
        "\t\tlabel = np.load(label_file)\n",
        "\t\treturn self.transforms(dicom), self.transforms(label)\n",
        "\n",
        "def axial_dataset_train(transforms, validation_ratio = 0.1):\n",
        "\tfiles = glob.glob(down_axial_training_data)\n",
        "\tassert len(files) > 0\n",
        "\tvalidation_files_count = ceil(len(files) * validation_ratio)\n",
        "\n",
        "\treturn (JawsDataset(files[validation_files_count:], transforms),\n",
        "\t\t\tJawsDataset(files[:validation_files_count], transforms))\n",
        "\n",
        "def coronal_dataset_train(transforms, validation_ratio = 0.1):\n",
        "\tfiles = glob.glob(down_coronal_training_data)\n",
        "\tassert len(files) > 0\n",
        "\tvalidation_files_count = ceil(len(files) * validation_ratio)\n",
        "\n",
        "\treturn (JawsDataset(files[validation_files_count:], transforms),\n",
        "\t\t\tJawsDataset(files[:validation_files_count], transforms))\n",
        "\n",
        "def sagittal_dataset_train(transforms, validation_ratio = 0.1):\n",
        "\tfiles = glob.glob(down_sagittal_training_data)\n",
        "\tassert len(files) > 0\n",
        "\tassert len(files) > 0\n",
        "\tvalidation_files_count = ceil(len(files) * validation_ratio)\n",
        "\n",
        "\treturn (JawsDataset(files[validation_files_count:], transforms),\n",
        "\t\t\tJawsDataset(files[:validation_files_count], transforms))\n",
        "\n",
        "def axial_dataset_test(transforms):\n",
        "\tfiles = glob.glob(down_axial_testing_data)\n",
        "\tassert len(files) > 0\n",
        "\treturn JawsDataset(files, transforms)\n",
        "\n",
        "def coronal_dataset_test(transforms):\n",
        "\tfiles = glob.glob(down_coronal_testing_data)\n",
        "\tassert len(files) > 0\n",
        "\treturn JawsDataset(files, transforms)\n",
        "\n",
        "def sagittal_dataset_test(transforms):\n",
        "\tfiles = glob.glob(down_sagittal_testing_data)\n",
        "\tassert len(files) > 0\n",
        "\treturn JawsDataset(files, transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO6_Mkt0OOAG"
      },
      "outputs": [],
      "source": [
        "dataset_transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize((128, 128)), transforms.Normalize(mean=[0.0], std=[1.0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmbmrQ0qOOAJ"
      },
      "outputs": [],
      "source": [
        "## take the name of any plane (axial or coronal or sagittal) and return train, validation and test datasets\n",
        "def get_plane_datasets(plane_type=\"axial\"):\n",
        "    if(plane_type.lower() == \"sagittal\"):\n",
        "        points_train_dataset, points_validation_dataset = sagittal_dataset_train(dataset_transforms)\n",
        "        points_test_dataset = sagittal_dataset_test(dataset_transforms)\n",
        "    elif(plane_type.lower() == \"coronal\"):\n",
        "        points_train_dataset, points_validation_dataset = coronal_dataset_train(dataset_transforms)\n",
        "        points_test_dataset = coronal_dataset_test(dataset_transforms)\n",
        "    else:\n",
        "        points_train_dataset, points_validation_dataset = axial_dataset_train(dataset_transforms)\n",
        "        points_test_dataset = axial_dataset_test(dataset_transforms)\n",
        "    return points_train_dataset, points_validation_dataset, points_test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuTZU6Rqrrgy"
      },
      "outputs": [],
      "source": [
        "##set the dataset into a dataloaders\n",
        "def get_plane_dataloader(train_ds, val_ds, test_ds):\n",
        "    train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=BATCH_SIZE)\n",
        "    val_loader = torch.utils.data.DataLoader(val_ds, shuffle=True, batch_size=BATCH_SIZE)\n",
        "    test_loader = torch.utils.data.DataLoader(test_ds, shuffle=True, batch_size=BATCH_SIZE)\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbz1cZSYOOAM"
      },
      "outputs": [],
      "source": [
        "## split loader into images and their masks\n",
        "def get_images_labels(data_loader):\n",
        "\tdata_iter = iter(data_loader)\n",
        "\timages, labels = data_iter.next()\n",
        "\treturn images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__7YMIGE-K2A"
      },
      "outputs": [],
      "source": [
        "## plot sample of the image and masks data\n",
        "def plot_images_labels(images, labels):\n",
        "    plt.figure(figsize=(16, 4))\n",
        "    for index in range(8, min(16, len(images))):\n",
        "        plt.subplot(2, 8, index + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(images[index].numpy().squeeze(), cmap='bone')\n",
        "        plt.imshow(labels[index].numpy().squeeze(), alpha=0.3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dataset.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "756e5570d4491bc9653f2b1746fdac04e7f8f2c613af5a9093a879035790827d"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}